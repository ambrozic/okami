{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction # Okami is a high-level web scraping framework built entirely for Python 3.6+ using asynchronous model provided by standard library asyncio module with aiohttp as a networking layer and lxml for parsing data. Architecture is entirely modular and main components can be swapped out and replaced with custom implementations. Features # complete website-wide page processing full scraping mode or delta mode scraping only unvisited pages immediate, on-demand or real-time page processing over HTTP API single page processing via command line lots of pipelines, middlewares and signals Spiders are very simple implementations. Take a look at an example here or continue to usage documentation page. License # Okami is licensed under a three clause BSD License. Full license text can be found here .","title":"Introduction"},{"location":"#introduction","text":"Okami is a high-level web scraping framework built entirely for Python 3.6+ using asynchronous model provided by standard library asyncio module with aiohttp as a networking layer and lxml for parsing data. Architecture is entirely modular and main components can be swapped out and replaced with custom implementations.","title":"Introduction"},{"location":"#features","text":"complete website-wide page processing full scraping mode or delta mode scraping only unvisited pages immediate, on-demand or real-time page processing over HTTP API single page processing via command line lots of pipelines, middlewares and signals Spiders are very simple implementations. Take a look at an example here or continue to usage documentation page.","title":"Features"},{"location":"#license","text":"Okami is licensed under a three clause BSD License. Full license text can be found here .","title":"License"},{"location":"contributing/","text":"Contributing # Thank you for taking the time to contribute! Visit repository page, make some noise in a form of an issue or a pull request and magical things will happen. Development # Okami installation for local development git clone https://github.com/ambrozic/okami cd okami python -m venv .venv source .venv/bin/activate make build","title":"Contributing"},{"location":"contributing/#contributing","text":"Thank you for taking the time to contribute! Visit repository page, make some noise in a form of an issue or a pull request and magical things will happen.","title":"Contributing"},{"location":"contributing/#development","text":"Okami installation for local development git clone https://github.com/ambrozic/okami cd okami python -m venv .venv source .venv/bin/activate make build","title":"Development"},{"location":"faq/","text":"FAQ # Frequently asked questions","title":"FAQ"},{"location":"faq/#faq","text":"Frequently asked questions","title":"FAQ"},{"location":"license/","text":"Copyright (c) Gregor Ambrozic and individual contributors. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. 3. The names of the contributors may not be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"License"},{"location":"releases/","text":"Releases # Version 0.2.0 # Released on 2018-08-08 Redesigned middleware and pipelines Redesigned storage Added delta scrape Removed clustering support Redesigned documentation Upgraded requirements Version 0.1.5 # Released on 2016-03-27 Upgraded requirements Version 0.1.0 # Released on 2016-03-01 First release","title":"Releases"},{"location":"releases/#releases","text":"","title":"Releases"},{"location":"releases/#version-020","text":"Released on 2018-08-08 Redesigned middleware and pipelines Redesigned storage Added delta scrape Removed clustering support Redesigned documentation Upgraded requirements","title":"Version 0.2.0"},{"location":"releases/#version-015","text":"Released on 2016-03-27 Upgraded requirements","title":"Version 0.1.5"},{"location":"releases/#version-010","text":"Released on 2016-03-01 First release","title":"Version 0.1.0"},{"location":"usage/","text":"We will try to run example web server and spider. Spider will process items from example web server. Install # pip install okami Settings # Use example OKAMI_SETTINGS export OKAMI_SETTINGS=okami.cfg.example Server # Run example web server okami example server Open localhost:8000 and browse around a little. Quite a remarkable website. We will run our example spider against this website shortly and process few items. Spider # Run example spider okami example spider Our example spider started and you can see it is processing pages. Take a look at an example spider implementation here . Project # To create a new project you will need the following: create python module for settings to be used as OKAMI_SETTINGS environment variable OKAMI_SETTINGS=okami.cfg.example create a module with your spiders and define it as SPIDERS in settings module SPIDERS=[\"path.to.package.spiders\"] That is all for now. Try and run your spider by executing following command in shell: OKAMI_SETTINGS=path.to.your.settings okami start spider-name Your spider should be running. Next step should be to check default settings , maybe set up your first pipeline or middleware and start collecting some data.","title":"Usage"},{"location":"usage/#install","text":"pip install okami","title":"Install"},{"location":"usage/#settings","text":"Use example OKAMI_SETTINGS export OKAMI_SETTINGS=okami.cfg.example","title":"Settings"},{"location":"usage/#server","text":"Run example web server okami example server Open localhost:8000 and browse around a little. Quite a remarkable website. We will run our example spider against this website shortly and process few items.","title":"Server"},{"location":"usage/#spider","text":"Run example spider okami example spider Our example spider started and you can see it is processing pages. Take a look at an example spider implementation here .","title":"Spider"},{"location":"usage/#project","text":"To create a new project you will need the following: create python module for settings to be used as OKAMI_SETTINGS environment variable OKAMI_SETTINGS=okami.cfg.example create a module with your spiders and define it as SPIDERS in settings module SPIDERS=[\"path.to.package.spiders\"] That is all for now. Try and run your spider by executing following command in shell: OKAMI_SETTINGS=path.to.your.settings okami start spider-name Your spider should be running. Next step should be to check default settings , maybe set up your first pipeline or middleware and start collecting some data.","title":"Project"},{"location":"docs/api/","text":"API # Reference of okami objects used most often. Downloader # Downloader <okami.Downloader> code github Item # Item <okami.Item> code github Request # Request <okami.Request> code github Response # Response <okami.Response> code github Spider # Spider <okami.Spider> code github Task # Task <okami.Task> code github Storage # Storage <okami.Storage> code github State # State <okami.api.State> Object is used in Throttle <okami.Throttle> custom implementation. code github Throttle # Throttle <okami.api.Throttle> code github","title":"API"},{"location":"docs/api/#api","text":"Reference of okami objects used most often.","title":"API"},{"location":"docs/api/#downloader","text":"Downloader <okami.Downloader> code github","title":"Downloader"},{"location":"docs/api/#item","text":"Item <okami.Item> code github","title":"Item"},{"location":"docs/api/#request","text":"Request <okami.Request> code github","title":"Request"},{"location":"docs/api/#response","text":"Response <okami.Response> code github","title":"Response"},{"location":"docs/api/#spider","text":"Spider <okami.Spider> code github","title":"Spider"},{"location":"docs/api/#task","text":"Task <okami.Task> code github","title":"Task"},{"location":"docs/api/#storage","text":"Storage <okami.Storage> code github","title":"Storage"},{"location":"docs/api/#state","text":"State <okami.api.State> Object is used in Throttle <okami.Throttle> custom implementation. code github","title":"State"},{"location":"docs/api/#throttle","text":"Throttle <okami.api.Throttle> code github","title":"Throttle"},{"location":"docs/architecture/","text":"Architecture # This page of the documentation explains technical details of okami architecture. Process # Initialising # Spider object is created and settings are loaded Pipelines and middlewares are loaded and initialised Startup pipeline is executed and finished Start page from spider is queued Scraping process starts. Processing # Request is created with a Task object Request is passed through http middleware before cycle Downloader processes Request and creates Response Response is passed through http middleware after cycle Errors from request/response cycle are handled as well as throttling Task and Response are passed through spider middleware before cycle Spider processes Task and Response and creates a list of new Task and Item objects Task , Response , list of Task and Item objects are passed through spider middleware after cycle List of Item objects is passed through items pipeline cycle List of Task objects is passed through tasks pipeline cycle Processing part is repeated for every task or page until exhausted. Finalising # Session object is closed Pipelines and middlewares are finalised Okami terminates. Schema #","title":"Architecture"},{"location":"docs/architecture/#architecture","text":"This page of the documentation explains technical details of okami architecture.","title":"Architecture"},{"location":"docs/architecture/#process","text":"","title":"Process"},{"location":"docs/architecture/#initialising","text":"Spider object is created and settings are loaded Pipelines and middlewares are loaded and initialised Startup pipeline is executed and finished Start page from spider is queued Scraping process starts.","title":"Initialising"},{"location":"docs/architecture/#processing","text":"Request is created with a Task object Request is passed through http middleware before cycle Downloader processes Request and creates Response Response is passed through http middleware after cycle Errors from request/response cycle are handled as well as throttling Task and Response are passed through spider middleware before cycle Spider processes Task and Response and creates a list of new Task and Item objects Task , Response , list of Task and Item objects are passed through spider middleware after cycle List of Item objects is passed through items pipeline cycle List of Task objects is passed through tasks pipeline cycle Processing part is repeated for every task or page until exhausted.","title":"Processing"},{"location":"docs/architecture/#finalising","text":"Session object is closed Pipelines and middlewares are finalised Okami terminates.","title":"Finalising"},{"location":"docs/architecture/#schema","text":"","title":"Schema"},{"location":"docs/cli/","text":"CLI # This page of the documentation will explain okami command line interface or CLI. Options # -h / --help print help or more information about each command -V / --version print okami version -s / --setup install okami bash completion Commands # Start # command okami start spider-name Runs okami application for a spider. $ okami start spider-name Okami: spider-name - delta = 0 .0001 sleep = 0 .0001 time = 0 .0002 rps = 0 .00 i = 0 - 0 /1/0/0 - 0 .02s Okami: spider-name - delta = 0 .0001 sleep = 0 .0001 time = 0 .0002 rps = 0 .00 i = 1 - 43 /45/0/0 - 0 .03s Okami: spider-name - delta = 0 .0108 sleep = 0 .0000 time = 0 .0109 rps = 91 .35 i = 2 - 90 /93/0/0 - 0 .04s ... List # command okami list Lists available spiders in project. $ okami list Spiders ( 3 ) spider1 okami.spider1:spider1 spider2 okami.spider2:spider2 spider3 okami.spider2:spider3 Server # command okami server Starts okami server . Server, by default, can be accessed at localhost:5566 . Use HTTP_SERVER_ADDRESS or command line arguments to define custom address and port. $ okami server Okami API Server at http://0.0.0.0:5566 Try an API HTTP call to okami server for example.com spider. Both okami server and okami example server should be running. $ http 'http://localhost:5566/process/?name=example.com&url=http://localhost:8000/men-backpacks/142000/' HTTP/1.1 200 OK Content-Length: 776 Content-Type: application/json ; charset = utf-8 Date: Fri, 23 Dec 2016 00 :00:00 GMT Server: Python/3.6 aiohttp/3.3.2 [ { \"category\" : \"men-backpacks\" , \"desc\" : \"some desc 142000\" , \"iid\" : 142000 , \"images\" : [ \"http://localhost:8000/images/name-4/4.png\" , \"http://localhost:8000/images/name-5/5.png\" , \"http://localhost:8000/images/name-6/6.png\" , \"http://localhost:8000/images/name-7/7.png\" , \"http://localhost:8000/images/name-8/8.png\" , \"http://localhost:8000/images/name-9/9.png\" , \"http://localhost:8000/images/name-10/10.png\" , \"http://localhost:8000/images/name-11/11.png\" , \"http://localhost:8000/images/name-12/12.png\" ] , \"name\" : \"name 142000\" , \"price\" : 48 .85, \"url\" : \"http://localhost:8000/men-backpacks/142000/\" } ] Process # command okami process spider-name Process a single url for spider-name from command line. It is crucial during development of spiders to test page processing. $ okami process example.com http://localhost:8000/women-belts/251000/ [ { \"category\" : \"women-belts\" , \"desc\" : \"some desc 251000\" , \"iid\" : 251000 , \"images\" : [ \"http://localhost:8000/images/name-4/4.png\" , \"http://localhost:8000/images/name-5/5.png\" , \"http://localhost:8000/images/name-6/6.png\" , \"http://localhost:8000/images/name-7/7.png\" , \"http://localhost:8000/images/name-8/8.png\" , \"http://localhost:8000/images/name-9/9.png\" , \"http://localhost:8000/images/name-10/10.png\" , \"http://localhost:8000/images/name-11/11.png\" , \"http://localhost:8000/images/name-12/12.png\" , \"http://localhost:8000/images/name-13/13.png\" ] , \"name\" : \"name 251000\" , \"price\" : 126 .64, \"url\" : \"http://localhost:8000/women-belts/251000/\" } ] Example # Server # command okami example server Runs example web server. $ okami example server Okami Example Server at http://localhost:8000/ - items: 2184 , delay: 0 .0 Spider # command okami example spider Runs example spider. It will run against example web server and process some data so make sure example server is running as well. $ okami example spider Okami: example.com - delta = 0 .0001 sleep = 0 .0001 time = 0 .0002 rps = 0 .00 i = 0 - 0 /1/0/0 - 0 .02s Okami: example.com - delta = 0 .0001 sleep = 0 .0001 time = 0 .0002 rps = 0 .00 i = 1 - 43 /45/0/0 - 0 .03s Okami: example.com - delta = 0 .0108 sleep = 0 .0000 time = 0 .0109 rps = 91 .35 i = 2 - 90 /93/0/0 - 0 .04s ... Profile # command okami server spider-name Profile application or spiders during development. It is using cProfile . Optionally, result can be exported into a file and used for more detailed analysis or visualisations. $ okami profile example.com Settings: OKAMI_SETTINGS: okami.cfg.example LOOP: <_UnixSelectorEventLoop running = False closed = False debug = False> DEBUG: False SPIDERS: [ 'okami' ] STORAGE: okami.Storage STORAGE_SETTINGS: {} CONN_MAX_CONCURRENT_REQUESTS: 10 REQUEST_MAX_FAILED: 50 REQUEST_MAX_PENDING: 10 THROTTLE: okami.Throttle THROTTLE_SETTINGS: { 'max_rps' : 500 } DELTA_ENABLED: False Results: 4477750 function calls ( 4472759 primitive calls ) in 7 .558 seconds Ordered by: cumulative time List reduced from 1159 to 232 due to restriction < 0 .2> ncalls tottime percall cumtime percall filename:lineno ( function ) 1 0 .000 0 .000 7 .561 7 .561 okami/engine.py:23 ( start ) 1 0 .000 0 .000 7 .559 7 .559 asyncio/base_events.py:432 ( run_until_complete ) 1 0 .011 0 .011 7 .559 7 .559 asyncio/base_events.py:404 ( run_forever ) 15615 0 .234 0 .000 7 .548 0 .000 asyncio/base_events.py:1335 ( _run_once ) 15621 0 .035 0 .000 6 .325 0 .000 asyncio/events.py:143 ( _run ) 4462 0 .044 0 .000 5 .883 0 .001 okami/engine.py:96 ( process ) 2229 0 .125 0 .000 3 .700 0 .002 okami/api.py:43 ( process ) 2229 0 .822 0 .000 2 .619 0 .001 okami/api.py:72 ( tasks ) 4462 0 .040 0 .000 1 .803 0 .000 okami/api.py:99 ( process ) 4462 0 .010 0 .000 1 .513 0 .000 aiohttp/client.py:842 ( __aenter__ ) 4462 0 .094 0 .000 1 .502 0 .000 aiohttp/client.py:222 ( _request ) 4458 1 .075 0 .000 1 .086 0 .000 lxml/html/__init__.py:759 ( document_fromstring ) 4458 0 .149 0 .000 1 .008 0 .000 okami/api.py:83 ( <setcomp> ) 2229 0 .393 0 .000 0 .969 0 .000 okami/example.py:32 ( items ) 15617 0 .045 0 .000 0 .944 0 .000 selectors.py:572 ( select ) 15623 0 .885 0 .000 0 .885 0 .000 { method 'control' of 'select.kqueue' objects } 100260 0 .087 0 .000 0 .538 0 .000 okami/utils.py:23 ( parse_domain_url ) 204986 0 .403 0 .000 0 .403 0 .000 { method 'match' of '_sre.SRE_Pattern' objects } ... Shell # command okami shell Just because. And it requires IPython to be installed. $ okami shell \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2551 \u2588\u2588\u2554\u255d\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2554\u2588\u2588\u2588\u2588\u2554\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2588\u2588\u2554\u255d\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2557\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u255d \u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u255d shell Python 3 .6.0 ( default, Dec 23 , 2016 , 00 :00:00 ) Type 'copyright' , 'credits' or 'license' for more information IPython 6 .5.0 -- An enhanced Interactive Python. Type '?' for help. In [ 1 ] :","title":"CLI"},{"location":"docs/cli/#cli","text":"This page of the documentation will explain okami command line interface or CLI.","title":"CLI"},{"location":"docs/cli/#options","text":"-h / --help print help or more information about each command -V / --version print okami version -s / --setup install okami bash completion","title":"Options"},{"location":"docs/cli/#commands","text":"","title":"Commands"},{"location":"docs/cli/#start","text":"command okami start spider-name Runs okami application for a spider. $ okami start spider-name Okami: spider-name - delta = 0 .0001 sleep = 0 .0001 time = 0 .0002 rps = 0 .00 i = 0 - 0 /1/0/0 - 0 .02s Okami: spider-name - delta = 0 .0001 sleep = 0 .0001 time = 0 .0002 rps = 0 .00 i = 1 - 43 /45/0/0 - 0 .03s Okami: spider-name - delta = 0 .0108 sleep = 0 .0000 time = 0 .0109 rps = 91 .35 i = 2 - 90 /93/0/0 - 0 .04s ...","title":"Start"},{"location":"docs/cli/#list","text":"command okami list Lists available spiders in project. $ okami list Spiders ( 3 ) spider1 okami.spider1:spider1 spider2 okami.spider2:spider2 spider3 okami.spider2:spider3","title":"List"},{"location":"docs/cli/#server","text":"command okami server Starts okami server . Server, by default, can be accessed at localhost:5566 . Use HTTP_SERVER_ADDRESS or command line arguments to define custom address and port. $ okami server Okami API Server at http://0.0.0.0:5566 Try an API HTTP call to okami server for example.com spider. Both okami server and okami example server should be running. $ http 'http://localhost:5566/process/?name=example.com&url=http://localhost:8000/men-backpacks/142000/' HTTP/1.1 200 OK Content-Length: 776 Content-Type: application/json ; charset = utf-8 Date: Fri, 23 Dec 2016 00 :00:00 GMT Server: Python/3.6 aiohttp/3.3.2 [ { \"category\" : \"men-backpacks\" , \"desc\" : \"some desc 142000\" , \"iid\" : 142000 , \"images\" : [ \"http://localhost:8000/images/name-4/4.png\" , \"http://localhost:8000/images/name-5/5.png\" , \"http://localhost:8000/images/name-6/6.png\" , \"http://localhost:8000/images/name-7/7.png\" , \"http://localhost:8000/images/name-8/8.png\" , \"http://localhost:8000/images/name-9/9.png\" , \"http://localhost:8000/images/name-10/10.png\" , \"http://localhost:8000/images/name-11/11.png\" , \"http://localhost:8000/images/name-12/12.png\" ] , \"name\" : \"name 142000\" , \"price\" : 48 .85, \"url\" : \"http://localhost:8000/men-backpacks/142000/\" } ]","title":"Server"},{"location":"docs/cli/#process","text":"command okami process spider-name Process a single url for spider-name from command line. It is crucial during development of spiders to test page processing. $ okami process example.com http://localhost:8000/women-belts/251000/ [ { \"category\" : \"women-belts\" , \"desc\" : \"some desc 251000\" , \"iid\" : 251000 , \"images\" : [ \"http://localhost:8000/images/name-4/4.png\" , \"http://localhost:8000/images/name-5/5.png\" , \"http://localhost:8000/images/name-6/6.png\" , \"http://localhost:8000/images/name-7/7.png\" , \"http://localhost:8000/images/name-8/8.png\" , \"http://localhost:8000/images/name-9/9.png\" , \"http://localhost:8000/images/name-10/10.png\" , \"http://localhost:8000/images/name-11/11.png\" , \"http://localhost:8000/images/name-12/12.png\" , \"http://localhost:8000/images/name-13/13.png\" ] , \"name\" : \"name 251000\" , \"price\" : 126 .64, \"url\" : \"http://localhost:8000/women-belts/251000/\" } ]","title":"Process"},{"location":"docs/cli/#example","text":"","title":"Example"},{"location":"docs/cli/#server_1","text":"command okami example server Runs example web server. $ okami example server Okami Example Server at http://localhost:8000/ - items: 2184 , delay: 0 .0","title":"Server"},{"location":"docs/cli/#spider","text":"command okami example spider Runs example spider. It will run against example web server and process some data so make sure example server is running as well. $ okami example spider Okami: example.com - delta = 0 .0001 sleep = 0 .0001 time = 0 .0002 rps = 0 .00 i = 0 - 0 /1/0/0 - 0 .02s Okami: example.com - delta = 0 .0001 sleep = 0 .0001 time = 0 .0002 rps = 0 .00 i = 1 - 43 /45/0/0 - 0 .03s Okami: example.com - delta = 0 .0108 sleep = 0 .0000 time = 0 .0109 rps = 91 .35 i = 2 - 90 /93/0/0 - 0 .04s ...","title":"Spider"},{"location":"docs/cli/#profile","text":"command okami server spider-name Profile application or spiders during development. It is using cProfile . Optionally, result can be exported into a file and used for more detailed analysis or visualisations. $ okami profile example.com Settings: OKAMI_SETTINGS: okami.cfg.example LOOP: <_UnixSelectorEventLoop running = False closed = False debug = False> DEBUG: False SPIDERS: [ 'okami' ] STORAGE: okami.Storage STORAGE_SETTINGS: {} CONN_MAX_CONCURRENT_REQUESTS: 10 REQUEST_MAX_FAILED: 50 REQUEST_MAX_PENDING: 10 THROTTLE: okami.Throttle THROTTLE_SETTINGS: { 'max_rps' : 500 } DELTA_ENABLED: False Results: 4477750 function calls ( 4472759 primitive calls ) in 7 .558 seconds Ordered by: cumulative time List reduced from 1159 to 232 due to restriction < 0 .2> ncalls tottime percall cumtime percall filename:lineno ( function ) 1 0 .000 0 .000 7 .561 7 .561 okami/engine.py:23 ( start ) 1 0 .000 0 .000 7 .559 7 .559 asyncio/base_events.py:432 ( run_until_complete ) 1 0 .011 0 .011 7 .559 7 .559 asyncio/base_events.py:404 ( run_forever ) 15615 0 .234 0 .000 7 .548 0 .000 asyncio/base_events.py:1335 ( _run_once ) 15621 0 .035 0 .000 6 .325 0 .000 asyncio/events.py:143 ( _run ) 4462 0 .044 0 .000 5 .883 0 .001 okami/engine.py:96 ( process ) 2229 0 .125 0 .000 3 .700 0 .002 okami/api.py:43 ( process ) 2229 0 .822 0 .000 2 .619 0 .001 okami/api.py:72 ( tasks ) 4462 0 .040 0 .000 1 .803 0 .000 okami/api.py:99 ( process ) 4462 0 .010 0 .000 1 .513 0 .000 aiohttp/client.py:842 ( __aenter__ ) 4462 0 .094 0 .000 1 .502 0 .000 aiohttp/client.py:222 ( _request ) 4458 1 .075 0 .000 1 .086 0 .000 lxml/html/__init__.py:759 ( document_fromstring ) 4458 0 .149 0 .000 1 .008 0 .000 okami/api.py:83 ( <setcomp> ) 2229 0 .393 0 .000 0 .969 0 .000 okami/example.py:32 ( items ) 15617 0 .045 0 .000 0 .944 0 .000 selectors.py:572 ( select ) 15623 0 .885 0 .000 0 .885 0 .000 { method 'control' of 'select.kqueue' objects } 100260 0 .087 0 .000 0 .538 0 .000 okami/utils.py:23 ( parse_domain_url ) 204986 0 .403 0 .000 0 .403 0 .000 { method 'match' of '_sre.SRE_Pattern' objects } ...","title":"Profile"},{"location":"docs/cli/#shell","text":"command okami shell Just because. And it requires IPython to be installed. $ okami shell \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2557\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2551 \u2588\u2588\u2554\u255d\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2554\u2588\u2588\u2588\u2588\u2554\u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2588\u2588\u2557 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2588\u2588\u2554\u255d\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2557\u2588\u2588\u2551 \u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u255d \u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u255d \u255a\u2550\u255d\u255a\u2550\u255d shell Python 3 .6.0 ( default, Dec 23 , 2016 , 00 :00:00 ) Type 'copyright' , 'credits' or 'license' for more information IPython 6 .5.0 -- An enhanced Interactive Python. Type '?' for help. In [ 1 ] :","title":"Shell"},{"location":"docs/downloader/","text":"Downloader # Receives a Request object from a http middleware before cycle and creates an HTTP request to a page. HTTP response is processed into a Response object, passed into http middleware after cycle and further into a spider for processing page data. Override DOWNLOADER class when you wish to define custom downloader functionality.","title":"Downloader"},{"location":"docs/downloader/#downloader","text":"Receives a Request object from a http middleware before cycle and creates an HTTP request to a page. HTTP response is processed into a Response object, passed into http middleware after cycle and further into a spider for processing page data. Override DOWNLOADER class when you wish to define custom downloader functionality.","title":"Downloader"},{"location":"docs/middlewares/","text":"Middlewares # Middleware is a recursive or two-way chain of processing elements. Input object is processed in a forward way and passed between middlewares and used to generate a result. Result is then processed backward and passed between middlewares in reverse order into final output object. Exceptions during middleware exceptions are important. Every middleware can raise an exception which terminates entire chain. If this is not a desirable option, middleware should catch and log or ignore exceptions. Okami runs several middlewares during spider initialisation and page processing cycle. There are several built-in middlewares and you can define your own middlewares. For a more visual representation on how middlewares are involved in processing cycle, check schema on architecture page. Http middleware # Http middleware wraps request/response and downloader cycle and runs for every page. Middlewares are defined as a tuple in settings as BASE_HTTP_MIDDLEWARE and HTTP_MIDDLEWARE and merged into a single tuple. First are executed BASE_HTTP_MIDDLEWARE , following are custom ones defined in HTTP_MIDDLEWARE . All phases involved in http middleware are described below. Initialise # Executes middleware initialise method at the beginning of scraping process when okami starts. Before # During before phase, middleware elements are executed in same order as defined in a tuple and are passed Request object. HttpMiddleware before method is called to process Request object. Final Request object is used by Downloader to create a Response object. After # Response is passed in after phase to middleware elements executed now in reverse order as defined in tuple. HttpMiddleware after method is called to process passed objects. Final Response object is then used for actual data processing. Finalise # Executes http middleware finalise method at the end of scraping process just before okami terminates. Spider middleware # Spider middleware wraps spider cycle and runs for every page. Middlewares are defined as a tuple in settings as BASE_SPIDER_MIDDLEWARE and SPIDER_MIDDLEWARE and merged into a single tuple. First are executed BASE_SPIDER_MIDDLEWARE , following are custom ones defined in SPIDER_MIDDLEWARE . All phases involved in spider middleware are described below. Initialise # Executes middleware initialise method at the beginning of scraping process when okami starts. Before # During before phase, middleware elements are executed in same order as defined in a tuple and are passed Task , Response object. SpiderMiddleware before method is called to process Response object. Final Request object is used by Spider to create a list of Task and a list of Item objects. After # Task , Response , a list of Task and a list of Item objects are passed in after phase to middleware elements executed now in reverse order as defined in tuple. SpiderMiddleware after is method called to process passed object. Final passed objects are then used in further request/response and downloader cycle as well as in TasksPipeline <okami.engine.TasksPipeline> and ItemsPipeline <okami.engine.ItemsPipeline> . Finalise # Executes spider middleware finalise method at the end of scraping process just before okami terminates.","title":"Middlewares"},{"location":"docs/middlewares/#middlewares","text":"Middleware is a recursive or two-way chain of processing elements. Input object is processed in a forward way and passed between middlewares and used to generate a result. Result is then processed backward and passed between middlewares in reverse order into final output object. Exceptions during middleware exceptions are important. Every middleware can raise an exception which terminates entire chain. If this is not a desirable option, middleware should catch and log or ignore exceptions. Okami runs several middlewares during spider initialisation and page processing cycle. There are several built-in middlewares and you can define your own middlewares. For a more visual representation on how middlewares are involved in processing cycle, check schema on architecture page.","title":"Middlewares"},{"location":"docs/middlewares/#http-middleware","text":"Http middleware wraps request/response and downloader cycle and runs for every page. Middlewares are defined as a tuple in settings as BASE_HTTP_MIDDLEWARE and HTTP_MIDDLEWARE and merged into a single tuple. First are executed BASE_HTTP_MIDDLEWARE , following are custom ones defined in HTTP_MIDDLEWARE . All phases involved in http middleware are described below.","title":"Http middleware"},{"location":"docs/middlewares/#initialise","text":"Executes middleware initialise method at the beginning of scraping process when okami starts.","title":"Initialise"},{"location":"docs/middlewares/#before","text":"During before phase, middleware elements are executed in same order as defined in a tuple and are passed Request object. HttpMiddleware before method is called to process Request object. Final Request object is used by Downloader to create a Response object.","title":"Before"},{"location":"docs/middlewares/#after","text":"Response is passed in after phase to middleware elements executed now in reverse order as defined in tuple. HttpMiddleware after method is called to process passed objects. Final Response object is then used for actual data processing.","title":"After"},{"location":"docs/middlewares/#finalise","text":"Executes http middleware finalise method at the end of scraping process just before okami terminates.","title":"Finalise"},{"location":"docs/middlewares/#spider-middleware","text":"Spider middleware wraps spider cycle and runs for every page. Middlewares are defined as a tuple in settings as BASE_SPIDER_MIDDLEWARE and SPIDER_MIDDLEWARE and merged into a single tuple. First are executed BASE_SPIDER_MIDDLEWARE , following are custom ones defined in SPIDER_MIDDLEWARE . All phases involved in spider middleware are described below.","title":"Spider middleware"},{"location":"docs/middlewares/#initialise_1","text":"Executes middleware initialise method at the beginning of scraping process when okami starts.","title":"Initialise"},{"location":"docs/middlewares/#before_1","text":"During before phase, middleware elements are executed in same order as defined in a tuple and are passed Task , Response object. SpiderMiddleware before method is called to process Response object. Final Request object is used by Spider to create a list of Task and a list of Item objects.","title":"Before"},{"location":"docs/middlewares/#after_1","text":"Task , Response , a list of Task and a list of Item objects are passed in after phase to middleware elements executed now in reverse order as defined in tuple. SpiderMiddleware after is method called to process passed object. Final passed objects are then used in further request/response and downloader cycle as well as in TasksPipeline <okami.engine.TasksPipeline> and ItemsPipeline <okami.engine.ItemsPipeline> .","title":"After"},{"location":"docs/middlewares/#finalise_1","text":"Executes spider middleware finalise method at the end of scraping process just before okami terminates.","title":"Finalise"},{"location":"docs/pipelines/","text":"Pipelines # In software engineering, a pipeline consists of a chain of processing elements (processes, threads, coroutines, functions, etc.), arranged so that the output of each element is the input of the next; the name is by analogy to a physical pipeline. \u2013 WikiPedia Each pipeline chain runs at a different frequency. Some only once i.e. at certain point in process, most are called after request is processed and some follow frequency settings. Pipelines are executed in same order as they are defined in settings . First executed are base pipelines following are custom ones. Each pipeline in a pipeline chain is passed same object. Object can be changed by each pipeline and a final version of passed object is returned by pipeline chain. Exceptions during pipeline are important. Every pipeline can raise an exception which terminates entire pipeline chain. If this is not a desirable option, pipelines should silently catch and log or ignore exceptions. Okami runs several pipelines during spider initialisation and page processing cycle. There are several built-in pipelines and you can define your own pipelines. For a more visual representation on how pipelines are involved in processing cycle, check schema on architecture page. Startup pipeline # Startup pipeline runs once when spider is initialised. STARTUP_PIPELINE tuple from settings defines a list of custom startup pipelines. Tuple order of pipelines is preserved during execution. All phases involved in startup pipeline are described below. Initialise # Executes pipeline initialise method at the beginning of scraping process when okami starts. Process # During process phase, pipeline process method is called to process Spider object. Finalise # Executes startup pipeline finalise method at the end of scraping process just before okami terminates. Items pipeline # Items pipeline runs every time after page at url is processed. Pipeline is processing a list of Item objects returned by spider. ITEMS_PIPELINE tuple from settings defines a list of custom items pipelines. Tuple order of pipelines is preserved during execution. All phases involved in items pipeline are described below. Initialise # Executes pipeline initialise method at the beginning of scraping process when okami starts. Process # During process phase, pipeline process method is called to process a set of Item objects. Finalise # Executes items pipeline finalise method at the end of scraping process just before okami terminates. Tasks pipeline # Tasks pipeline runs every time after page at url is processed. Pipeline is processing a list of Task objects returned by spider and used for queuing and further processing. TASKS_PIPELINE tuple from settings defines a list of custom tasks pipelines. Tuple order of pipelines is preserved during execution. All phases involved in tasks pipeline are described below. Initialise # Executes pipeline initialise method at the beginning of scraping process when okami starts. Process # During process phase, pipeline process method is called to process a set of Task objects. Finalise # Executes tasks pipeline finalise method at the end of scraping process just before okami terminates.","title":"Pipelines"},{"location":"docs/pipelines/#pipelines","text":"In software engineering, a pipeline consists of a chain of processing elements (processes, threads, coroutines, functions, etc.), arranged so that the output of each element is the input of the next; the name is by analogy to a physical pipeline. \u2013 WikiPedia Each pipeline chain runs at a different frequency. Some only once i.e. at certain point in process, most are called after request is processed and some follow frequency settings. Pipelines are executed in same order as they are defined in settings . First executed are base pipelines following are custom ones. Each pipeline in a pipeline chain is passed same object. Object can be changed by each pipeline and a final version of passed object is returned by pipeline chain. Exceptions during pipeline are important. Every pipeline can raise an exception which terminates entire pipeline chain. If this is not a desirable option, pipelines should silently catch and log or ignore exceptions. Okami runs several pipelines during spider initialisation and page processing cycle. There are several built-in pipelines and you can define your own pipelines. For a more visual representation on how pipelines are involved in processing cycle, check schema on architecture page.","title":"Pipelines"},{"location":"docs/pipelines/#startup-pipeline","text":"Startup pipeline runs once when spider is initialised. STARTUP_PIPELINE tuple from settings defines a list of custom startup pipelines. Tuple order of pipelines is preserved during execution. All phases involved in startup pipeline are described below.","title":"Startup pipeline"},{"location":"docs/pipelines/#initialise","text":"Executes pipeline initialise method at the beginning of scraping process when okami starts.","title":"Initialise"},{"location":"docs/pipelines/#process","text":"During process phase, pipeline process method is called to process Spider object.","title":"Process"},{"location":"docs/pipelines/#finalise","text":"Executes startup pipeline finalise method at the end of scraping process just before okami terminates.","title":"Finalise"},{"location":"docs/pipelines/#items-pipeline","text":"Items pipeline runs every time after page at url is processed. Pipeline is processing a list of Item objects returned by spider. ITEMS_PIPELINE tuple from settings defines a list of custom items pipelines. Tuple order of pipelines is preserved during execution. All phases involved in items pipeline are described below.","title":"Items pipeline"},{"location":"docs/pipelines/#initialise_1","text":"Executes pipeline initialise method at the beginning of scraping process when okami starts.","title":"Initialise"},{"location":"docs/pipelines/#process_1","text":"During process phase, pipeline process method is called to process a set of Item objects.","title":"Process"},{"location":"docs/pipelines/#finalise_1","text":"Executes items pipeline finalise method at the end of scraping process just before okami terminates.","title":"Finalise"},{"location":"docs/pipelines/#tasks-pipeline","text":"Tasks pipeline runs every time after page at url is processed. Pipeline is processing a list of Task objects returned by spider and used for queuing and further processing. TASKS_PIPELINE tuple from settings defines a list of custom tasks pipelines. Tuple order of pipelines is preserved during execution. All phases involved in tasks pipeline are described below.","title":"Tasks pipeline"},{"location":"docs/pipelines/#initialise_2","text":"Executes pipeline initialise method at the beginning of scraping process when okami starts.","title":"Initialise"},{"location":"docs/pipelines/#process_2","text":"During process phase, pipeline process method is called to process a set of Task objects.","title":"Process"},{"location":"docs/pipelines/#finalise_2","text":"Executes tasks pipeline finalise method at the end of scraping process just before okami terminates.","title":"Finalise"},{"location":"docs/server/","text":"Server # Okami server is a service to process in real time pages on a website implemented by spider. Override HTTP_SERVER class when you wish to define custom server functionality. Start # okami server Access Okami server at localhost:5566 . Use HTTP_SERVER_ADDRESS or command line arguments to define custom address and port. Endpoints # /process/ method GET parameters name spider name url page url example /process/?name=example.com&url=http://example.com/product/id/","title":"Server"},{"location":"docs/server/#server","text":"Okami server is a service to process in real time pages on a website implemented by spider. Override HTTP_SERVER class when you wish to define custom server functionality.","title":"Server"},{"location":"docs/server/#start","text":"okami server Access Okami server at localhost:5566 . Use HTTP_SERVER_ADDRESS or command line arguments to define custom address and port.","title":"Start"},{"location":"docs/server/#endpoints","text":"/process/ method GET parameters name spider name url page url example /process/?name=example.com&url=http://example.com/product/id/","title":"Endpoints"},{"location":"docs/settings/","text":"Settings # Settings can be defined as OKAMI_SETTINGS environment variable otherwise default settings will be loaded. It should be set like this export OKAMI_SETTINGS=okami.cfg.example or passed with command OKAMI_SETTINGS=okami.cfg.example okami command To import okami settings in your project use this from okami import settings . # Below are available okami settings located in okami.cfg.default module with default values. VERSION # Current okami version DEBUG # Enable debugging for asyncio module. Check Debug mode of asyncio documentation. default DEBUG = False SPIDERS # List of python modules in your project containing spider implementations available to okami. default SPIDERS = [] STORAGE # Storage class path and name default STORAGE = \"okami.Storage\" DOWNLOADER # Downloader class path and name default DOWNLOADER = \"okami.Downloader\" HTTP_SERVER # HTTP server class path and name default HTTP_SERVER = \"okami.server.Server\" THROTTLE # Throttle class path and name default THROTTLE = \"okami.Throttle\" STORAGE_SETTINGS # Arguments passed to storage module default STORAGE_SETTINGS = {} THROTTLE_SETTINGS # Arguments passed to throttle module default THROTTLE_SETTINGS = {} HTTP_SERVER_ADDRESS # HTTP server default address default HTTP_SERVER_ADDRESS = \"0.0.0.0:5566\" USER_AGENT # Default USER-AGENT used in requests default USER_AGENT = \"Okami/{}\".format(okami.__version__) EVENT_LOOP_POLICY # Set a custom event loop policy object. Check Customizing the event loop policy documentation. default EVENT_LOOP_POLICY = None ASYNC_TIMEOUT # Asyncio Future object timeout. Check concurrent.futures.wait documentation. default ASYNC_TIMEOUT = 10 ASYNC_SLOW_CALLBACK_DURATION # Asyncio minimum duration in seconds of slow callbacks. Check Debug mode of asyncio documentation. default ASYNC_SLOW_CALLBACK_DURATION = 0.1 PAUSE_TIMEOUT # Pause timeout, in case of server connection errors etc. okami pauses scraping default PAUSE_TIMEOUT = 5 CONN_TIMEOUT # Connection timeout default CONN_TIMEOUT = 20 CONN_VERIFY_SSL # SSL verification for HTTP requests default CONN_VERIFY_SSL = False CONN_MAX_CONCURRENT_CONNECTIONS # Maximum number of concurrent connections to website default CONN_MAX_CONCURRENT_CONNECTIONS = 5 CONN_MAX_CONCURRENT_REQUESTS # Maximum number of concurrent requests to website. Effectively an async loop size. default CONN_MAX_CONCURRENT_REQUESTS = 10 CONN_MAX_RETRIES # Maximum number of connection retries in case of connection issues default CONN_MAX_RETRIES = 5 CONN_MAX_HTTP_REDIRECTS # Maximum number of HTTP redirects default CONN_MAX_HTTP_REDIRECTS = 10 REQUEST_MAX_FAILED # Maximum number of failed requests before okami stops default REQUEST_MAX_FAILED = 50 REQUEST_MAX_PENDING # Maximum number of pending requests before logging an error default REQUEST_MAX_PENDING = 10 BASE_HTTP_MIDDLEWARE # List of base http middleware. Should not change. default BASE_HTTP_MIDDLEWARE = ( \"okami.middleware.Session\", \"okami.middleware.Headers\", ) HTTP_MIDDLEWARE # List of http middleware. Use to add custom handlers. default HTTP_MIDDLEWARE = () BASE_SPIDER_MIDDLEWARE # List of base spider middleware. Should not change. default BASE_SPIDER_MIDDLEWARE = () SPIDER_MIDDLEWARE # List of spider middleware. Use to add custom handlers. default SPIDER_MIDDLEWARE = () BASE_STARTUP_PIPELINE # List of base startup pipelines. Should not change. default BASE_STARTUP_PIPELINE = () STARTUP_PIPELINE # List of startup pipelines. Use to add custom handlers. default STARTUP_PIPELINE = () BASE_ITEMS_PIPELINE # List of base items pipelines. Should not change. default BASE_ITEMS_PIPELINE = () ITEMS_PIPELINE # List of items pipelines. Use to add custom handlers. default ITEMS_PIPELINE = () BASE_TASKS_PIPELINE # List of base tasks pipelines. Should not change. default BASE_TASKS_PIPELINE = () TASKS_PIPELINE # List of tasks pipelines. Use to add custom handlers. default TASKS_PIPELINE = () DELTA_ENABLED # Delta middleware enable default DELTA_ENABLED = False DELTA_PATH # Delta middleware database directory. Defaults to current directory. default DELTA_PATH = None","title":"Settings"},{"location":"docs/settings/#settings","text":"Settings can be defined as OKAMI_SETTINGS environment variable otherwise default settings will be loaded. It should be set like this export OKAMI_SETTINGS=okami.cfg.example or passed with command OKAMI_SETTINGS=okami.cfg.example okami command To import okami settings in your project use this from okami import settings .","title":"Settings"},{"location":"docs/settings/#version","text":"Current okami version","title":"VERSION"},{"location":"docs/settings/#debug","text":"Enable debugging for asyncio module. Check Debug mode of asyncio documentation. default DEBUG = False","title":"DEBUG"},{"location":"docs/settings/#spiders","text":"List of python modules in your project containing spider implementations available to okami. default SPIDERS = []","title":"SPIDERS"},{"location":"docs/settings/#storage","text":"Storage class path and name default STORAGE = \"okami.Storage\"","title":"STORAGE"},{"location":"docs/settings/#downloader","text":"Downloader class path and name default DOWNLOADER = \"okami.Downloader\"","title":"DOWNLOADER"},{"location":"docs/settings/#http_server","text":"HTTP server class path and name default HTTP_SERVER = \"okami.server.Server\"","title":"HTTP_SERVER"},{"location":"docs/settings/#throttle","text":"Throttle class path and name default THROTTLE = \"okami.Throttle\"","title":"THROTTLE"},{"location":"docs/settings/#storage_settings","text":"Arguments passed to storage module default STORAGE_SETTINGS = {}","title":"STORAGE_SETTINGS"},{"location":"docs/settings/#throttle_settings","text":"Arguments passed to throttle module default THROTTLE_SETTINGS = {}","title":"THROTTLE_SETTINGS"},{"location":"docs/settings/#http_server_address","text":"HTTP server default address default HTTP_SERVER_ADDRESS = \"0.0.0.0:5566\"","title":"HTTP_SERVER_ADDRESS"},{"location":"docs/settings/#user_agent","text":"Default USER-AGENT used in requests default USER_AGENT = \"Okami/{}\".format(okami.__version__)","title":"USER_AGENT"},{"location":"docs/settings/#event_loop_policy","text":"Set a custom event loop policy object. Check Customizing the event loop policy documentation. default EVENT_LOOP_POLICY = None","title":"EVENT_LOOP_POLICY"},{"location":"docs/settings/#async_timeout","text":"Asyncio Future object timeout. Check concurrent.futures.wait documentation. default ASYNC_TIMEOUT = 10","title":"ASYNC_TIMEOUT"},{"location":"docs/settings/#async_slow_callback_duration","text":"Asyncio minimum duration in seconds of slow callbacks. Check Debug mode of asyncio documentation. default ASYNC_SLOW_CALLBACK_DURATION = 0.1","title":"ASYNC_SLOW_CALLBACK_DURATION"},{"location":"docs/settings/#pause_timeout","text":"Pause timeout, in case of server connection errors etc. okami pauses scraping default PAUSE_TIMEOUT = 5","title":"PAUSE_TIMEOUT"},{"location":"docs/settings/#conn_timeout","text":"Connection timeout default CONN_TIMEOUT = 20","title":"CONN_TIMEOUT"},{"location":"docs/settings/#conn_verify_ssl","text":"SSL verification for HTTP requests default CONN_VERIFY_SSL = False","title":"CONN_VERIFY_SSL"},{"location":"docs/settings/#conn_max_concurrent_connections","text":"Maximum number of concurrent connections to website default CONN_MAX_CONCURRENT_CONNECTIONS = 5","title":"CONN_MAX_CONCURRENT_CONNECTIONS"},{"location":"docs/settings/#conn_max_concurrent_requests","text":"Maximum number of concurrent requests to website. Effectively an async loop size. default CONN_MAX_CONCURRENT_REQUESTS = 10","title":"CONN_MAX_CONCURRENT_REQUESTS"},{"location":"docs/settings/#conn_max_retries","text":"Maximum number of connection retries in case of connection issues default CONN_MAX_RETRIES = 5","title":"CONN_MAX_RETRIES"},{"location":"docs/settings/#conn_max_http_redirects","text":"Maximum number of HTTP redirects default CONN_MAX_HTTP_REDIRECTS = 10","title":"CONN_MAX_HTTP_REDIRECTS"},{"location":"docs/settings/#request_max_failed","text":"Maximum number of failed requests before okami stops default REQUEST_MAX_FAILED = 50","title":"REQUEST_MAX_FAILED"},{"location":"docs/settings/#request_max_pending","text":"Maximum number of pending requests before logging an error default REQUEST_MAX_PENDING = 10","title":"REQUEST_MAX_PENDING"},{"location":"docs/settings/#base_http_middleware","text":"List of base http middleware. Should not change. default BASE_HTTP_MIDDLEWARE = ( \"okami.middleware.Session\", \"okami.middleware.Headers\", )","title":"BASE_HTTP_MIDDLEWARE"},{"location":"docs/settings/#http_middleware","text":"List of http middleware. Use to add custom handlers. default HTTP_MIDDLEWARE = ()","title":"HTTP_MIDDLEWARE"},{"location":"docs/settings/#base_spider_middleware","text":"List of base spider middleware. Should not change. default BASE_SPIDER_MIDDLEWARE = ()","title":"BASE_SPIDER_MIDDLEWARE"},{"location":"docs/settings/#spider_middleware","text":"List of spider middleware. Use to add custom handlers. default SPIDER_MIDDLEWARE = ()","title":"SPIDER_MIDDLEWARE"},{"location":"docs/settings/#base_startup_pipeline","text":"List of base startup pipelines. Should not change. default BASE_STARTUP_PIPELINE = ()","title":"BASE_STARTUP_PIPELINE"},{"location":"docs/settings/#startup_pipeline","text":"List of startup pipelines. Use to add custom handlers. default STARTUP_PIPELINE = ()","title":"STARTUP_PIPELINE"},{"location":"docs/settings/#base_items_pipeline","text":"List of base items pipelines. Should not change. default BASE_ITEMS_PIPELINE = ()","title":"BASE_ITEMS_PIPELINE"},{"location":"docs/settings/#items_pipeline","text":"List of items pipelines. Use to add custom handlers. default ITEMS_PIPELINE = ()","title":"ITEMS_PIPELINE"},{"location":"docs/settings/#base_tasks_pipeline","text":"List of base tasks pipelines. Should not change. default BASE_TASKS_PIPELINE = ()","title":"BASE_TASKS_PIPELINE"},{"location":"docs/settings/#tasks_pipeline","text":"List of tasks pipelines. Use to add custom handlers. default TASKS_PIPELINE = ()","title":"TASKS_PIPELINE"},{"location":"docs/settings/#delta_enabled","text":"Delta middleware enable default DELTA_ENABLED = False","title":"DELTA_ENABLED"},{"location":"docs/settings/#delta_path","text":"Delta middleware database directory. Defaults to current directory. default DELTA_PATH = None","title":"DELTA_PATH"},{"location":"docs/signals/","text":"Signals # Okami includes a signal dispatcher which allows applications to get notified when actions occur somewhere in okami framework. Signals allow certain senders to notify a set of receivers that some action has taken place. They\u2019re especially useful when many pieces of code may be interested in the same events. Receiving signals # In code example below, function response_created connects to signal signals.response_created by being decorated with signals.receiver . Function response_created will be called every time signal signals.response_created is executed. from okami import signals @signals.receiver ( signals . response_created ) async def response_created ( signal , sender , ** kwargs ): print ( \"response_created: {}, {}, {}\" . format ( signal , sender , kwargs )) Configuration # Configuration is a bit awkward because of the way python decorators work. Make sure your signal receivers are imported at some point in your project otherwise add from your.app import signals somewhere, i.e. in your top __init__.py module. Available signals # Okami provides a set of built-in signals. Http middleware signals # http_middleware_initialised http_middleware_started http_middleware_finished http_middleware_finalised Spider middleware signals # spider_middleware_initialised spider_middleware_started spider_middleware_finished spider_middleware_finalised Downloader signals # response_created Startup pipeline signals # startup_pipeline_initialised startup_pipeline_started startup_pipeline_finished startup_pipeline_finalised Items pipeline signals # items_pipeline_initialised items_pipeline_started items_pipeline_finished items_pipeline_finalised Tasks pipeline signals # tasks_pipeline_initialised tasks_pipeline_started tasks_pipeline_finished tasks_pipeline_finalised","title":"Signals"},{"location":"docs/signals/#signals","text":"Okami includes a signal dispatcher which allows applications to get notified when actions occur somewhere in okami framework. Signals allow certain senders to notify a set of receivers that some action has taken place. They\u2019re especially useful when many pieces of code may be interested in the same events.","title":"Signals"},{"location":"docs/signals/#receiving-signals","text":"In code example below, function response_created connects to signal signals.response_created by being decorated with signals.receiver . Function response_created will be called every time signal signals.response_created is executed. from okami import signals @signals.receiver ( signals . response_created ) async def response_created ( signal , sender , ** kwargs ): print ( \"response_created: {}, {}, {}\" . format ( signal , sender , kwargs ))","title":"Receiving signals"},{"location":"docs/signals/#configuration","text":"Configuration is a bit awkward because of the way python decorators work. Make sure your signal receivers are imported at some point in your project otherwise add from your.app import signals somewhere, i.e. in your top __init__.py module.","title":"Configuration"},{"location":"docs/signals/#available-signals","text":"Okami provides a set of built-in signals.","title":"Available signals"},{"location":"docs/signals/#http-middleware-signals","text":"http_middleware_initialised http_middleware_started http_middleware_finished http_middleware_finalised","title":"Http middleware signals"},{"location":"docs/signals/#spider-middleware-signals","text":"spider_middleware_initialised spider_middleware_started spider_middleware_finished spider_middleware_finalised","title":"Spider middleware signals"},{"location":"docs/signals/#downloader-signals","text":"response_created","title":"Downloader signals"},{"location":"docs/signals/#startup-pipeline-signals","text":"startup_pipeline_initialised startup_pipeline_started startup_pipeline_finished startup_pipeline_finalised","title":"Startup pipeline signals"},{"location":"docs/signals/#items-pipeline-signals","text":"items_pipeline_initialised items_pipeline_started items_pipeline_finished items_pipeline_finalised","title":"Items pipeline signals"},{"location":"docs/signals/#tasks-pipeline-signals","text":"tasks_pipeline_initialised tasks_pipeline_started tasks_pipeline_finished tasks_pipeline_finalised","title":"Tasks pipeline signals"},{"location":"docs/spiders/","text":"Spiders # Spiders are the business end of okami. Their main function is to provide URL parsing rules and web page content parsing for a particular web page. Spiders are fed Task and Response object after HttpMiddleware and Downloader are finished processing Request object for a page. Response object contains complete HTTP response. Spiders, if needed, can also handle authentication and session for HTTP negotiation with website. Full scraping cycle is defined in process section on architecture page. Notes # Spiders should have unique class property name . Keep your spiders in a python package. You can have multiple packages. Define them in settings module. SPIDERS=[\"path.to.package.spiders\"] Okami finds and loads spiders from this packages using property name . Development # Make sure everything is properly configured. During development you can test run your spider using command below: okami process spider-name url This will run a spider with name spider-name against a page at url . Output should be a JSON representation of a list of Item objects. Details # Below are required and optional implementation details for every spider. Required # Spider.name - required and it should be unique Spider.urls dictionary defines rules used by okami to parse a list of valid URLs from page content for further website processing. Spider.urls.start - URLs used as starting URLs for processing website Spider.urls.allow - Allowed URLs for further website processing Spider.urls.avoid - URLs that are avoided during website processing Spider.items <okami.Spider.items> method receives Task object, processes page content and returns a list of Item objects. Optional # Spider.tasks <okami.Spider.tasks> method is optionally used in case Spider.urls does not get all URLs. Method receives Task object, processes page content and returns a list of Task objects with urls and optionally data for further processing. Spider.session <okami.Spider.session> method is optionally used to handle authentication etc. Spider.request <okami.Spider.request> method is optionally used to define a dictionary of extra arguments passed into Request object used by Downloader to create an HTTP request and download a page Spider.delta <okami.Spider.hash> method is optionally used to provide a custom delta key in case delta scraping mode is enabled Example # Below is an example Spider implementation. class Example ( Spider ) : \"\"\" An example Spider implementation. \"\"\" name = \"example.com\" urls = dict ( start = [ \"http://localhost:8000/\" ], allow = [ \"//nav//a/@href\" , \"//div[@id='product-list']//div//a/@href\" , ], avoid = [ \"//a[contains(@href, '/about/')]/@href\" , \"//a[contains(@href, '/sale/')]/@href\" , ] ) async def items ( self , task , response ) : items = [] document = lxml . html . document_fromstring ( html = response . text ) products = document . xpath ( \"//div[@class='product']\" ) for product in products : iid = int ( product . xpath ( \".//@product-id\" )[ 0 ]) name = product . xpath ( \".//h2/text()\" )[ 0 ] desc = product . xpath ( \".//p/text()\" )[ 0 ] category = product . xpath ( \".//span/text()\" )[ 0 ] price = float ( product . xpath ( \".//em/text()\" )[ 0 ]) images = product . xpath ( \".//div//img/@src\" ) item = Product ( iid = iid , url = str ( response . url ), name = name , category = category , desc = desc , price = price , images = images , ) items . append ( item ) return items And an example Item implementation. class Product ( Item ) : \"\"\" An example Item object implementation. You will of course have your own. \"\"\" def __init__ ( self , iid , url , name , category , desc , price , images = None ) : self . iid = iid self . url = url self . name = name self . category = category self . desc = desc self . price = price self . images = images or [] def to_dict ( self ) : return dict ( iid = self . iid , url = self . url , name = self . name , category = self . category , desc = self . desc , price = self . price , images = self . images , )","title":"Spiders"},{"location":"docs/spiders/#spiders","text":"Spiders are the business end of okami. Their main function is to provide URL parsing rules and web page content parsing for a particular web page. Spiders are fed Task and Response object after HttpMiddleware and Downloader are finished processing Request object for a page. Response object contains complete HTTP response. Spiders, if needed, can also handle authentication and session for HTTP negotiation with website. Full scraping cycle is defined in process section on architecture page.","title":"Spiders"},{"location":"docs/spiders/#notes","text":"Spiders should have unique class property name . Keep your spiders in a python package. You can have multiple packages. Define them in settings module. SPIDERS=[\"path.to.package.spiders\"] Okami finds and loads spiders from this packages using property name .","title":"Notes"},{"location":"docs/spiders/#development","text":"Make sure everything is properly configured. During development you can test run your spider using command below: okami process spider-name url This will run a spider with name spider-name against a page at url . Output should be a JSON representation of a list of Item objects.","title":"Development"},{"location":"docs/spiders/#details","text":"Below are required and optional implementation details for every spider.","title":"Details"},{"location":"docs/spiders/#required","text":"Spider.name - required and it should be unique Spider.urls dictionary defines rules used by okami to parse a list of valid URLs from page content for further website processing. Spider.urls.start - URLs used as starting URLs for processing website Spider.urls.allow - Allowed URLs for further website processing Spider.urls.avoid - URLs that are avoided during website processing Spider.items <okami.Spider.items> method receives Task object, processes page content and returns a list of Item objects.","title":"Required"},{"location":"docs/spiders/#optional","text":"Spider.tasks <okami.Spider.tasks> method is optionally used in case Spider.urls does not get all URLs. Method receives Task object, processes page content and returns a list of Task objects with urls and optionally data for further processing. Spider.session <okami.Spider.session> method is optionally used to handle authentication etc. Spider.request <okami.Spider.request> method is optionally used to define a dictionary of extra arguments passed into Request object used by Downloader to create an HTTP request and download a page Spider.delta <okami.Spider.hash> method is optionally used to provide a custom delta key in case delta scraping mode is enabled","title":"Optional"},{"location":"docs/spiders/#example","text":"Below is an example Spider implementation. class Example ( Spider ) : \"\"\" An example Spider implementation. \"\"\" name = \"example.com\" urls = dict ( start = [ \"http://localhost:8000/\" ], allow = [ \"//nav//a/@href\" , \"//div[@id='product-list']//div//a/@href\" , ], avoid = [ \"//a[contains(@href, '/about/')]/@href\" , \"//a[contains(@href, '/sale/')]/@href\" , ] ) async def items ( self , task , response ) : items = [] document = lxml . html . document_fromstring ( html = response . text ) products = document . xpath ( \"//div[@class='product']\" ) for product in products : iid = int ( product . xpath ( \".//@product-id\" )[ 0 ]) name = product . xpath ( \".//h2/text()\" )[ 0 ] desc = product . xpath ( \".//p/text()\" )[ 0 ] category = product . xpath ( \".//span/text()\" )[ 0 ] price = float ( product . xpath ( \".//em/text()\" )[ 0 ]) images = product . xpath ( \".//div//img/@src\" ) item = Product ( iid = iid , url = str ( response . url ), name = name , category = category , desc = desc , price = price , images = images , ) items . append ( item ) return items And an example Item implementation. class Product ( Item ) : \"\"\" An example Item object implementation. You will of course have your own. \"\"\" def __init__ ( self , iid , url , name , category , desc , price , images = None ) : self . iid = iid self . url = url self . name = name self . category = category self . desc = desc self . price = price self . images = images or [] def to_dict ( self ) : return dict ( iid = self . iid , url = self . url , name = self . name , category = self . category , desc = self . desc , price = self . price , images = self . images , )","title":"Example"},{"location":"docs/storage/","text":"Storage # Okami needs to keep internal state. okami.storage.BaseStorage <okami.storage.BaseStorage> module is used as an API. By default, Storage is used. Override STORAGE class if you wish to define custom storage functionality.","title":"Storage"},{"location":"docs/storage/#storage","text":"Okami needs to keep internal state. okami.storage.BaseStorage <okami.storage.BaseStorage> module is used as an API. By default, Storage is used. Override STORAGE class if you wish to define custom storage functionality.","title":"Storage"},{"location":"docs/throttling/","text":"Throttling # In software, a throttling process, or a throttling controller as it is sometimes called, is a process responsible for regulating the rate at which application processing is conducted, either statically or dynamically. \u2013 WikiPedia Okami is controlling processing throughput using class Throttle . Throttle keeps track of processed items and response times for every iteration using this values to calculate next iteration. Throttle can control maximum RPS (requests per second) or sleep time directly for every iteration. It supports dynamic calculation for both of this values i.e. increasing or decreasing iteration sleep value based on responsiveness (page response time) of a website being processed. Customise # Use THROTTLE_SETTINGS from settings module. # set fixed sleep time THROTTLE_SETTINGS = dict ( sleep = 0.001 ) # or set RPS limit THROTTLE_SETTINGS = dict ( max_rps = 20 ) # or use dynamic sleep time calculation THROTTLE_SETTINGS = dict ( fn = lambda state : 0.2 if state . delta > 2.0 else 0.001 ) Function for custom control is passed a State object with current values. Returned value is a float object, a sleep time used in next iteration. Override # Override THROTTLE class when you wish to define custom throttling functionality.","title":"Throttling"},{"location":"docs/throttling/#throttling","text":"In software, a throttling process, or a throttling controller as it is sometimes called, is a process responsible for regulating the rate at which application processing is conducted, either statically or dynamically. \u2013 WikiPedia Okami is controlling processing throughput using class Throttle . Throttle keeps track of processed items and response times for every iteration using this values to calculate next iteration. Throttle can control maximum RPS (requests per second) or sleep time directly for every iteration. It supports dynamic calculation for both of this values i.e. increasing or decreasing iteration sleep value based on responsiveness (page response time) of a website being processed.","title":"Throttling"},{"location":"docs/throttling/#customise","text":"Use THROTTLE_SETTINGS from settings module. # set fixed sleep time THROTTLE_SETTINGS = dict ( sleep = 0.001 ) # or set RPS limit THROTTLE_SETTINGS = dict ( max_rps = 20 ) # or use dynamic sleep time calculation THROTTLE_SETTINGS = dict ( fn = lambda state : 0.2 if state . delta > 2.0 else 0.001 ) Function for custom control is passed a State object with current values. Returned value is a float object, a sleep time used in next iteration.","title":"Customise"},{"location":"docs/throttling/#override","text":"Override THROTTLE class when you wish to define custom throttling functionality.","title":"Override"}]}